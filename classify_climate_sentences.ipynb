{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifying climate related sentences\n",
    "\n",
    "In this project I attempt to determine to what extent British newspapers misreport information about climate change. To do so I implement the following steps:\n",
    "- Manually classify a set of news articles at the sentence level\n",
    "- Use this set to fine-tune the pre-trained Bert model\n",
    "- Use the fine-tuned model to predict classes for the remaining articles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The sample for training\n",
    "\n",
    "After scraping from Nexis the universe of British news articles that contain either \"*climate change*\" or \"*global warming*\", I first divided the sample into topics using LDA (code not reported here). The rationale is simple: *climate change* or *global warming* appear in a wide variety of contexts, e.g. when reporting about floods, hurricanes, or when reporting about current energy policy issues or also when reporting simply about politics, as the issue is often mentioned in political agendas. Therefore I want to manually classify articles not just randomly from the whole sample, but randomizing within topics, according to the weight each topic has in the sample. A concrete example: a topic which I labeled \"Extreme weather events\" accounts for $12\\%$ of all the articles. Therefore if I want to classify manually $100$ articles, $12$ of them will be randomly selected from this topic.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.random.seed(1337)\n",
    "import datetime\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import keras\n",
    "from keras.models import Model\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import manually classified sample\n",
    "dir = \"/mypath/\"\n",
    "df_to_use = pd.read_excel(dir+\"sample_manual2.xlsx\", engine='openpyxl', sheet_name=\"Sheet1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the dataset articles are split into sentences, which are then manually classified as follows:\n",
    "- if sentence is aligned with scientific consensus on climate change: 1\n",
    "- if sentence is not aligned with scientific consensus on climate change: -1\n",
    "- if sentence is not at all related with climate science: 2\n",
    "\n",
    "Being *aligned with scientific consensus* means reporting facts discovered by the scientific community. Here are some examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     This enabled the BBC yet again to claim that A...\n",
       "26     The onset of global warming poses real concer...\n",
       "27     If gales, floods and droughts are to become m...\n",
       "28     According to an ABI report published last mon...\n",
       "31     By the 2050s, East Anglia's coastline is expe...\n",
       "Name: Transcript, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_to_use['Transcript'][df_to_use['Score']==1].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead, sentences labelled with $-1$ are generally those that:\n",
    "- negate statements made by climate scientists\n",
    "- report climate science as unsettled, i.e. as if there is an ongoing debate\n",
    "- use ironic language to refer to climate scientists\n",
    "\n",
    "See here some examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38987    Global temperatures stopped rising 15 years ag...\n",
       "38988    Needless to add, support of global warming ala...\n",
       "38989    Why should we believe what the IPCC predicts, ...\n",
       "38990    Recent global warming has actually helped to r...\n",
       "38991    The more CO2 there is in the air, the better p...\n",
       "Name: Transcript, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_to_use['Transcript'][df_to_use['Score']==-1].tail(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look quickly at what this sample looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 2    33988\n",
       " 1     4442\n",
       "-1      562\n",
       "Name: Score, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How many 1s, -1s and 2s are in the sample?\n",
    "df_to_use['Score'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 2    6000\n",
       " 1    4442\n",
       "-1     562\n",
       "Name: Score, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Since the sample is highly unbalanced we can get rid of some sentences not related to climate science\n",
    "# Even a smaller number should be enough\n",
    "aux = df_to_use.loc[df_to_use['Score']==2] # Keep only the 2s\n",
    "aux = aux.sample(n=6000, random_state = 4) # 6000 should be enough\n",
    "aux2 = df_to_use.loc[df_to_use['Score']!=2]\n",
    "df_to_use = aux.append(aux2)               # Rebuild the dataset for use\n",
    "df_to_use['Score'].value_counts()          # Re-check how many sentences we have now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x15000b810>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Let's just keep the columns of interest\n",
    "train_raw = df_to_use[['Transcript','Score']]\n",
    "\n",
    "# See the distribution of the labels\n",
    "train_raw['Score'].value_counts().sort_values(ascending=False).plot(kind='bar')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>30828</td>\n",
       "      <td>As we approach World Food Day this ­coming Mo...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23303</td>\n",
       "      <td>We can do something as a government</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32494</td>\n",
       "      <td>The results reveal that Scandinavian countrie...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28201</td>\n",
       "      <td>If there were any doubts about the Coalition'...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37664</td>\n",
       "      <td>But the Prime Minister has been hit by a back...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  label\n",
       "30828   As we approach World Food Day this ­coming Mo...      2\n",
       "23303                We can do something as a government      2\n",
       "32494   The results reveal that Scandinavian countrie...      2\n",
       "28201   If there were any doubts about the Coalition'...      2\n",
       "37664   But the Prime Minister has been hit by a back...      2"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rename the columns\n",
    "train_raw=train_raw.rename(columns = {'Transcript':'text', 'Score':'label'})\n",
    "train_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Let's relabel the labels\n",
    "LE = LabelEncoder()\n",
    "train_raw['label'] = LE.fit_transform(train_raw['label'])\n",
    "\n",
    "# Make taining set copy\n",
    "train = train_raw.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>30828</td>\n",
       "      <td>as we approach world food day this coming mon...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23303</td>\n",
       "      <td>we can do something as government</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32494</td>\n",
       "      <td>the results reveal that scandinavian countrie...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28201</td>\n",
       "      <td>if there were any doubts about the coalitions...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37664</td>\n",
       "      <td>but the prime minister has been hit by backla...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  label\n",
       "30828   as we approach world food day this coming mon...      2\n",
       "23303                  we can do something as government      2\n",
       "32494   the results reveal that scandinavian countrie...      2\n",
       "28201   if there were any doubts about the coalitions...      2\n",
       "37664   but the prime minister has been hit by backla...      2"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Clean the text column a bit\n",
    "import re\n",
    "\n",
    "def clean_txt(text):\n",
    "    text = re.sub(\"'\",\"\",text)\n",
    "    text = re.sub(\"(\\\\W)+\",\" \",text)\n",
    "    text = re.sub(r'\\s+[a-zA-Z]\\s+', ' ', text)\n",
    "    text = re.sub(r'\\s+', ' ', text, flags=re.I)\n",
    "    text = re.sub(r'\\s*(?:[\\w_]*_(?:[\\w_]*_)*[\\w_]*)', '', text)\n",
    "    text = re.sub(r'\\s*(?:[\\w_]*[0-9+](?:[\\w_]*[0-9+])*[\\w_]*)', '', text)\n",
    "    text = text.lower()\n",
    "    return text\n",
    "\n",
    "train['text'] = train.text.apply(clean_txt)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training and validation sets (80/20 proportion)\n",
    "from sklearn.model_selection import train_test_split\n",
    "train, val = train_test_split(train, test_size=0.2, random_state=35)\n",
    "\n",
    "# Re-index the datasets\n",
    "train.reset_index(drop=True, inplace=True)\n",
    "val.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/magreco/opt/anaconda3/lib/python3.7/site-packages/bert/optimization.py:87: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import bert\n",
    "from bert import run_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Model output directory: ./bert_news_category *****\n"
     ]
    }
   ],
   "source": [
    "### Setting now the output directory for BERT\n",
    "\n",
    "# Set the output directory for saving model file\n",
    "OUTPUT_DIR = './bert_news_category'\n",
    "\n",
    "#@markdown Whether or not to clear/delete the directory and create a new one\n",
    "DO_DELETE = True #@param {type:\"boolean\"}\n",
    "\n",
    "if DO_DELETE:\n",
    "  try:\n",
    "    tf.gfile.DeleteRecursively(OUTPUT_DIR)\n",
    "  except:\n",
    "    pass\n",
    "\n",
    "tf.gfile.MakeDirs(OUTPUT_DIR)\n",
    "print('***** Model output directory: {} *****'.format(OUTPUT_DIR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_COLUMN = 'text'\n",
    "LABEL_COLUMN = 'label'\n",
    "\n",
    "# The list containing all the classes (train['SECTION'].unique())\n",
    "label_list = [x for x in np.unique(train.label)]\n",
    "label_list # now -1 has become 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As BERT cannot handle text longer than 250 tokens, we must define a funcion in case the text exceeds this limit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Splitting the Data into smaller chunks\n",
    "# If a text is longer than 250 words, it will be split in 200 words chunks with 50 words overlap\n",
    "\n",
    "def get_split(text1):\n",
    "  l_total = []\n",
    "  l_parcial = []\n",
    "  # // (floor division) divides and returns the integer value of the quotient\n",
    "  if len(text1.split())//150 >0:\n",
    "    n = len(text1.split())//150\n",
    "  else: \n",
    "    n = 1\n",
    "  for w in range(n):\n",
    "    if w == 0:\n",
    "      l_parcial = text1.split()[:200]\n",
    "      l_total.append(\" \".join(l_parcial))\n",
    "    else:\n",
    "      l_parcial = text1.split()[w*150:w*150 + 200]\n",
    "      l_total.append(\" \".join(l_parcial))\n",
    "  return l_total\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>text_split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>this will be the first time weve actually eli...</td>\n",
       "      <td>1</td>\n",
       "      <td>[this will be the first time weve actually eli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>thousands of homes across the uk are without ...</td>\n",
       "      <td>2</td>\n",
       "      <td>[thousands of homes across the uk are without ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label  \\\n",
       "0   this will be the first time weve actually eli...      1   \n",
       "1   thousands of homes across the uk are without ...      2   \n",
       "\n",
       "                                          text_split  \n",
       "0  [this will be the first time weve actually eli...  \n",
       "1  [thousands of homes across the uk are without ...  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply the split to our training and validation datasets\n",
    "train['text_split'] = train[DATA_COLUMN].apply(get_split)\n",
    "train.head(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>text_split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>there is overwhelming evidence that habitat l...</td>\n",
       "      <td>1</td>\n",
       "      <td>[there is overwhelming evidence that habitat l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>though scientists have studied this behaviour...</td>\n",
       "      <td>2</td>\n",
       "      <td>[though scientists have studied this behaviour...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label  \\\n",
       "0   there is overwhelming evidence that habitat l...      1   \n",
       "1   though scientists have studied this behaviour...      2   \n",
       "\n",
       "                                          text_split  \n",
       "0  [there is overwhelming evidence that habitat l...  \n",
       "1  [though scientists have studied this behaviour...  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val['text_split'] = val[DATA_COLUMN].apply(get_split)\n",
    "val.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8804, 8804, 8804)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Adjust the labels in case of split text\n",
    "# For training set\n",
    "train_l = []\n",
    "label_l = []\n",
    "index_l =[]\n",
    "for idx,row in train.iterrows():\n",
    "  for l in row['text_split']:\n",
    "    train_l.append(l)\n",
    "    label_l.append(row['label'])\n",
    "    index_l.append(idx)\n",
    "len(train_l), len(label_l), len(index_l)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2201, 2201, 2201)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For validation set\n",
    "val_l = []\n",
    "val_label_l = []\n",
    "val_index_l = []\n",
    "for idx,row in val.iterrows():\n",
    "  for l in row['text_split']:\n",
    "    val_l.append(l)\n",
    "    val_label_l.append(row['label'])\n",
    "    val_index_l.append(idx)\n",
    "len(val_l), len(val_label_l), len(val_index_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    4805\n",
       "1    3549\n",
       "0     450\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The final dataset for training\n",
    "train_df = pd.DataFrame({DATA_COLUMN:train_l, LABEL_COLUMN:label_l})\n",
    "train_df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    1196\n",
       "1     893\n",
       "0     112\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The final dataset for validation\n",
    "val_df = pd.DataFrame({DATA_COLUMN:val_l, LABEL_COLUMN:val_label_l})\n",
    "val_df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "## BERT: Data Preprocessing\n",
    "\n",
    "# Process the data for BERT\n",
    "train_InputExamples = train_df.apply(lambda x: bert.run_classifier.InputExample(guid=None,\n",
    "                                                                   text_a = x[DATA_COLUMN], \n",
    "                                                                   text_b = None, \n",
    "                                                                   label = x[LABEL_COLUMN]), axis = 1)\n",
    "\n",
    "val_InputExamples = val_df.apply(lambda x: bert.run_classifier.InputExample(guid=None, \n",
    "                                                                   text_a = x[DATA_COLUMN], \n",
    "                                                                   text_b = None, \n",
    "                                                                   label = x[LABEL_COLUMN]), axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/magreco/opt/anaconda3/lib/python3.7/site-packages/bert/tokenization.py:125: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/magreco/opt/anaconda3/lib/python3.7/site-packages/bert/tokenization.py:125: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## BERT: Loading the pre-trained model\n",
    "# This is a path to an uncased (all lowercase) version of BERT\n",
    "BERT_MODEL_HUB = \"https://tfhub.dev/google/bert_uncased_L-12_H-768_A-12/1\"\n",
    "\n",
    "\n",
    "def create_tokenizer_from_hub_module():\n",
    "  \"\"\"Get the vocab file and casing info from the Hub module.\"\"\"\n",
    "  with tf.Graph().as_default():\n",
    "    bert_module = hub.Module(BERT_MODEL_HUB)\n",
    "    tokenization_info = bert_module(signature=\"tokenization_info\", as_dict=True)\n",
    "    with tf.Session() as sess:\n",
    "      vocab_file, do_lower_case = sess.run([tokenization_info[\"vocab_file\"],\n",
    "                                            tokenization_info[\"do_lower_case\"]])\n",
    "      \n",
    "  return bert.tokenization.FullTokenizer(\n",
    "      vocab_file=vocab_file, do_lower_case=do_lower_case)\n",
    "\n",
    "\n",
    "tokenizer = create_tokenizer_from_hub_module()\n",
    "# Here you may get an error and may have to execute in the terminal 'rm -rf path-to-folder'\n",
    "# (this removes the 'incriminated folder')\n",
    "# Then re-run here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['this', 'will', 'be', 'the', 'first', 'time', 'we', '##ve', 'actually', 'eliminated', 'an', 'entire', 'ecosystem']\n"
     ]
    }
   ],
   "source": [
    "#Here is what the tokenised sample of the first training set observation looks like\n",
    "print(tokenizer.tokenize(train_InputExamples.iloc[0].text_a))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/magreco/opt/anaconda3/lib/python3.7/site-packages/bert/run_classifier.py:774: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/magreco/opt/anaconda3/lib/python3.7/site-packages/bert/run_classifier.py:774: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Writing example 0 of 8804\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Writing example 0 of 8804\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] this will be the first time we ##ve actually eliminated an entire ecosystem [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] this will be the first time we ##ve actually eliminated an entire ecosystem [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 2023 2097 2022 1996 2034 2051 2057 3726 2941 5892 2019 2972 16927 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 2023 2097 2022 1996 2034 2051 2057 3726 2941 5892 2019 2972 16927 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 1 (id = 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 1 (id = 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] thousands of homes across the uk are without power and many roads are still imp ##ass ##able as britain continues to shiver [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] thousands of homes across the uk are without power and many roads are still imp ##ass ##able as britain continues to shiver [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 5190 1997 5014 2408 1996 2866 2024 2302 2373 1998 2116 4925 2024 2145 17727 12054 3085 2004 3725 4247 2000 13277 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 5190 1997 5014 2408 1996 2866 2024 2302 2373 1998 2116 4925 2024 2145 17727 12054 3085 2004 3725 4247 2000 13277 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 2 (id = 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 2 (id = 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] climate talks in paris this month are our last chance to turn the tide [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] climate talks in paris this month are our last chance to turn the tide [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 4785 7566 1999 3000 2023 3204 2024 2256 2197 3382 2000 2735 1996 10401 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 4785 7566 1999 3000 2023 3204 2024 2256 2197 3382 2000 2735 1996 10401 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 1 (id = 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 1 (id = 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] if so global warming may have started just in time [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] if so global warming may have started just in time [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 2065 2061 3795 12959 2089 2031 2318 2074 1999 2051 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 2065 2061 3795 12959 2089 2031 2318 2074 1999 2051 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] it also looks beyond the kyoto commitment period of and uses the domestic goal as the spur for further action to cut emissions that will set britain on what is regarded as more sustainable path by encouraging move to less carbon dependent economy [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] it also looks beyond the kyoto commitment period of and uses the domestic goal as the spur for further action to cut emissions that will set britain on what is regarded as more sustainable path by encouraging move to less carbon dependent economy [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 2009 2036 3504 3458 1996 15008 8426 2558 1997 1998 3594 1996 4968 3125 2004 1996 12996 2005 2582 2895 2000 3013 11768 2008 2097 2275 3725 2006 2054 2003 5240 2004 2062 9084 4130 2011 11434 2693 2000 2625 6351 7790 4610 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 2009 2036 3504 3458 1996 15008 8426 2558 1997 1998 3594 1996 4968 3125 2004 1996 12996 2005 2582 2895 2000 3013 11768 2008 2097 2275 3725 2006 2054 2003 5240 2004 2062 9084 4130 2011 11434 2693 2000 2625 6351 7790 4610 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 1 (id = 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 1 (id = 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Writing example 0 of 2201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Writing example 0 of 2201\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] there is overwhelming evidence that habitat loss and fragmentation over exploitation of biological resources pollution species invasions and climate change have increased rates of global species extinction ##s to levels that are much higher than those observed in the fossil record [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] there is overwhelming evidence that habitat loss and fragmentation over exploitation of biological resources pollution species invasions and climate change have increased rates of global species extinction ##s to levels that are much higher than those observed in the fossil record [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 2045 2003 10827 3350 2008 6552 3279 1998 28424 2058 14427 1997 6897 4219 10796 2427 23536 1998 4785 2689 2031 3445 6165 1997 3795 2427 14446 2015 2000 3798 2008 2024 2172 3020 2084 2216 5159 1999 1996 10725 2501 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 2045 2003 10827 3350 2008 6552 3279 1998 28424 2058 14427 1997 6897 4219 10796 2427 23536 1998 4785 2689 2031 3445 6165 1997 3795 2427 14446 2015 2000 3798 2008 2024 2172 3020 2084 2216 5159 1999 1996 10725 2501 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 1 (id = 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 1 (id = 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] though scientists have studied this behaviour since the seeing it first hand was dramatic experience for the researchers [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] though scientists have studied this behaviour since the seeing it first hand was dramatic experience for the researchers [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 2295 6529 2031 3273 2023 9164 2144 1996 3773 2009 2034 2192 2001 6918 3325 2005 1996 6950 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 2295 6529 2031 3273 2023 9164 2144 1996 3773 2009 2034 2192 2001 6918 3325 2005 1996 6950 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 2 (id = 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 2 (id = 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] some time ago gps told the minister that there was crisis in general practice [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] some time ago gps told the minister that there was crisis in general practice [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 2070 2051 3283 14658 2409 1996 2704 2008 2045 2001 5325 1999 2236 3218 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 2070 2051 3283 14658 2409 1996 2704 2008 2045 2001 5325 1999 2236 3218 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 2 (id = 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 2 (id = 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] browne first joined the company in as an apprentice and worked his way up taking the top job in [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] browne first joined the company in as an apprentice and worked his way up taking the top job in [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 15005 2034 2587 1996 2194 1999 2004 2019 13357 1998 2499 2010 2126 2039 2635 1996 2327 3105 1999 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 15005 2034 2587 1996 2194 1999 2004 2019 13357 1998 2499 2010 2126 2039 2635 1996 2327 3105 1999 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 2 (id = 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 2 (id = 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] and majority per cent said the us should join other countries in setting standards to address global climate change [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] and majority per cent said the us should join other countries in setting standards to address global climate change [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 1998 3484 2566 9358 2056 1996 2149 2323 3693 2060 3032 1999 4292 4781 2000 4769 3795 4785 2689 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 1998 3484 2566 9358 2056 1996 2149 2323 3693 2060 3032 1999 4292 4781 2000 4769 3795 4785 2689 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 1 (id = 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 1 (id = 1)\n"
     ]
    }
   ],
   "source": [
    "# Convert our train and validation features to InputFeatures that BERT understands.\n",
    "MAX_SEQ_LENGTH = 200\n",
    "\n",
    "train_features = bert.run_classifier.convert_examples_to_features(train_InputExamples, label_list, MAX_SEQ_LENGTH, tokenizer)\n",
    "\n",
    "val_features = bert.run_classifier.convert_examples_to_features(val_InputExamples, label_list, MAX_SEQ_LENGTH, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "## BERT: Creating A Multi-Class Classifier Model\n",
    "def create_model(is_predicting, input_ids, input_mask, segment_ids, labels,\n",
    "                 num_labels):\n",
    "  \n",
    "  bert_module = hub.Module(\n",
    "      BERT_MODEL_HUB,\n",
    "      trainable=True)\n",
    "  bert_inputs = dict(\n",
    "      input_ids=input_ids,\n",
    "      input_mask=input_mask,\n",
    "      segment_ids=segment_ids)\n",
    "  bert_outputs = bert_module(\n",
    "      inputs=bert_inputs,\n",
    "      signature=\"tokens\",\n",
    "      as_dict=True)\n",
    "\n",
    "  # Use \"pooled_output\" for classification tasks on an entire sentence.\n",
    "  # Use \"sequence_outputs\" for token-level output.\n",
    "  output_layer = bert_outputs[\"pooled_output\"]\n",
    "  # with tf.Session() as sess:\n",
    "  output_layer1 = bert_outputs[\"pooled_output\"]\n",
    "  # output_layer1 = 999\n",
    "  hidden_size = output_layer.shape[-1].value\n",
    "\n",
    "  # Create our own layer to tune for politeness data.\n",
    "  output_weights = tf.get_variable(\n",
    "      \"output_weights\", [num_labels, hidden_size],\n",
    "      initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "\n",
    "  output_bias = tf.get_variable(\n",
    "      \"output_bias\", [num_labels], initializer=tf.zeros_initializer())\n",
    "\n",
    "  with tf.variable_scope(\"loss\"):\n",
    "\n",
    "    # Dropout helps prevent overfitting\n",
    "    output_layer = tf.nn.dropout(output_layer, keep_prob=0.8)\n",
    "\n",
    "    logits = tf.matmul(output_layer, output_weights, transpose_b=True)\n",
    "    logits = tf.nn.bias_add(logits, output_bias)\n",
    "    log_probs = tf.nn.log_softmax(logits, axis=-1)\n",
    "\n",
    "    # Convert labels into one-hot encoding\n",
    "    one_hot_labels = tf.one_hot(labels, depth=num_labels, dtype=tf.float32)\n",
    "\n",
    "    predicted_labels = tf.squeeze(tf.argmax(log_probs, axis=-1, output_type=tf.int32))\n",
    "    # If we're predicting, we want predicted labels and the probabiltiies\n",
    "    if is_predicting:\n",
    "      return (predicted_labels, log_probs, output_layer1)\n",
    "\n",
    "    # If we're train/eval, compute loss between predicted and actual label\n",
    "    per_example_loss = -tf.reduce_sum(one_hot_labels * log_probs, axis=-1)\n",
    "    loss = tf.reduce_mean(per_example_loss)\n",
    "    return (loss, predicted_labels, log_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_fn_builder(num_labels, learning_rate, num_train_steps,\n",
    "                     num_warmup_steps):\n",
    "  \"\"\"Returns `model_fn` closure for TPUEstimator.\"\"\"\n",
    "  def model_fn(features, labels, mode, params):  # pylint: disable=unused-argument\n",
    "    \"\"\"The `model_fn` for TPUEstimator.\"\"\"\n",
    "\n",
    "    input_ids = features[\"input_ids\"]\n",
    "    input_mask = features[\"input_mask\"]\n",
    "    segment_ids = features[\"segment_ids\"]\n",
    "    label_ids = features[\"label_ids\"]\n",
    "\n",
    "    is_predicting = (mode == tf.estimator.ModeKeys.PREDICT)\n",
    "    \n",
    "    # TRAIN and EVAL\n",
    "    if not is_predicting:\n",
    "\n",
    "      (loss, predicted_labels, log_probs) = create_model(\n",
    "        is_predicting, input_ids, input_mask, segment_ids, label_ids, num_labels)\n",
    "\n",
    "      train_op = bert.optimization.create_optimizer(\n",
    "          loss, learning_rate, num_train_steps, num_warmup_steps, use_tpu=False)\n",
    "\n",
    "      # Calculate evaluation metrics. \n",
    "      def metric_fn(label_ids, predicted_labels):\n",
    "        accuracy = tf.metrics.accuracy(label_ids, predicted_labels)\n",
    "        true_pos = tf.metrics.true_positives(\n",
    "            label_ids,\n",
    "            predicted_labels)\n",
    "        true_neg = tf.metrics.true_negatives(\n",
    "            label_ids,\n",
    "            predicted_labels)   \n",
    "        false_pos = tf.metrics.false_positives(\n",
    "            label_ids,\n",
    "            predicted_labels)  \n",
    "        false_neg = tf.metrics.false_negatives(\n",
    "            label_ids,\n",
    "            predicted_labels)\n",
    "        \n",
    "        return {\n",
    "            \"eval_accuracy\": accuracy,\n",
    "            \"true_positives\": true_pos,\n",
    "            \"true_negatives\": true_neg,\n",
    "            \"false_positives\": false_pos,\n",
    "            \"false_negatives\": false_neg,\n",
    "            }\n",
    "\n",
    "      eval_metrics = metric_fn(label_ids, predicted_labels)\n",
    "\n",
    "      if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        return tf.estimator.EstimatorSpec(mode=mode,\n",
    "          loss=loss,\n",
    "          train_op=train_op)\n",
    "      else:\n",
    "          return tf.estimator.EstimatorSpec(mode=mode,\n",
    "            loss=loss,\n",
    "            eval_metric_ops=eval_metrics)\n",
    "    else:\n",
    "      (predicted_labels, log_probs, output_layer) = create_model(\n",
    "        is_predicting, input_ids, input_mask, segment_ids, label_ids, num_labels)\n",
    "      predictions = {\n",
    "          'probabilities': log_probs,\n",
    "          'labels': predicted_labels,\n",
    "          'pooled_output': output_layer\n",
    "      }\n",
    "      return tf.estimator.EstimatorSpec(mode, predictions=predictions)\n",
    "\n",
    "  # Return the actual model function in the closure\n",
    "  return model_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(550, 3)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Specify the size of the batches, the learning rate and the number of epochs\n",
    "BATCH_SIZE = 16\n",
    "LEARNING_RATE = 2e-5\n",
    "NUM_TRAIN_EPOCHS = 1.0\n",
    "# Warmup is a period of time where the learning rate is small and gradually increases--usually helps training.\n",
    "WARMUP_PROPORTION = 0.1\n",
    "# Model configs\n",
    "SAVE_CHECKPOINTS_STEPS = 300\n",
    "SAVE_SUMMARY_STEPS = 100\n",
    "\n",
    "# Compute train and warmup steps from batch size\n",
    "num_train_steps = int(len(train_features) / BATCH_SIZE * NUM_TRAIN_EPOCHS)\n",
    "num_warmup_steps = int(num_train_steps * WARMUP_PROPORTION)\n",
    "\n",
    "# Specify output directory and number of checkpoint steps to save\n",
    "run_config = tf.estimator.RunConfig(\n",
    "    model_dir=OUTPUT_DIR,\n",
    "    save_summary_steps=SAVE_SUMMARY_STEPS,\n",
    "    save_checkpoints_steps=SAVE_CHECKPOINTS_STEPS)\n",
    "\n",
    "# Specify output directory and number of checkpoint steps to save\n",
    "run_config = tf.estimator.RunConfig(\n",
    "    model_dir=OUTPUT_DIR,\n",
    "    save_summary_steps=SAVE_SUMMARY_STEPS,\n",
    "    save_checkpoints_steps=SAVE_CHECKPOINTS_STEPS)\n",
    "\n",
    "num_train_steps, len(label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_model_dir': './bert_news_category', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 300, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x150d9ed90>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_model_dir': './bert_news_category', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 300, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x150d9ed90>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "#Initializing the model and the estimator\n",
    "model_fn = model_fn_builder(\n",
    "  num_labels=len(label_list),\n",
    "  learning_rate=LEARNING_RATE,\n",
    "  num_train_steps=num_train_steps,\n",
    "  num_warmup_steps=num_warmup_steps)\n",
    "\n",
    "estimator = tf.estimator.Estimator(\n",
    "  model_fn=model_fn,\n",
    "  config=run_config,\n",
    "  params={\"batch_size\": BATCH_SIZE})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an input function for training. drop_remainder = True for using TPUs.\n",
    "train_input_fn = bert.run_classifier.input_fn_builder(\n",
    "    features=train_features,\n",
    "    seq_length=MAX_SEQ_LENGTH,\n",
    "    is_training=True,\n",
    "    drop_remainder=False)\n",
    "\n",
    "# Create an input function for validating. drop_remainder = True for using TPUs.\n",
    "val_input_fn = run_classifier.input_fn_builder(\n",
    "    features=val_features,\n",
    "    seq_length=MAX_SEQ_LENGTH,\n",
    "    is_training=False,\n",
    "    drop_remainder=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning Training!\n",
      "WARNING:tensorflow:From /Users/magreco/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/magreco/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-37-63361cb6a0ba>:36: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-37-63361cb6a0ba>:36: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/magreco/opt/anaconda3/lib/python3.7/site-packages/bert/optimization.py:27: The name tf.train.get_or_create_global_step is deprecated. Please use tf.compat.v1.train.get_or_create_global_step instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/magreco/opt/anaconda3/lib/python3.7/site-packages/bert/optimization.py:27: The name tf.train.get_or_create_global_step is deprecated. Please use tf.compat.v1.train.get_or_create_global_step instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/magreco/opt/anaconda3/lib/python3.7/site-packages/bert/optimization.py:32: The name tf.train.polynomial_decay is deprecated. Please use tf.compat.v1.train.polynomial_decay instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/magreco/opt/anaconda3/lib/python3.7/site-packages/bert/optimization.py:32: The name tf.train.polynomial_decay is deprecated. Please use tf.compat.v1.train.polynomial_decay instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/magreco/opt/anaconda3/lib/python3.7/site-packages/bert/optimization.py:70: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/magreco/opt/anaconda3/lib/python3.7/site-packages/bert/optimization.py:70: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/magreco/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/math_grad.py:1375: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/magreco/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/math_grad.py:1375: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "/Users/magreco/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 0 into ./bert_news_category/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 0 into ./bert_news_category/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 1.4090145, step = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 1.4090145, step = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 39 vs previous value: 39. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 39 vs previous value: 39. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 93 vs previous value: 93. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 93 vs previous value: 93. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 95 vs previous value: 95. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 95 vs previous value: 95. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 0.101758\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 0.101758\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.4747469, step = 101 (982.755 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.4747469, step = 101 (982.755 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 0.103997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 0.103997\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.3452792, step = 201 (961.569 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.3452792, step = 201 (961.569 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 300 into ./bert_news_category/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 300 into ./bert_news_category/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 0.103342\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 0.103342\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.74722993, step = 301 (967.638 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.74722993, step = 301 (967.638 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 0.104478\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 0.104478\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.38982016, step = 401 (957.167 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.38982016, step = 401 (957.167 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 0.106544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 0.106544\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.56318367, step = 501 (938.549 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.56318367, step = 501 (938.549 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 550 into ./bert_news_category/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 550 into ./bert_news_category/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Loss for final step: 0.27117813.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Loss for final step: 0.27117813.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training took time  1:28:38.635908\n"
     ]
    }
   ],
   "source": [
    "### BERT: Fine Tuning Training & Evaluating ###\n",
    "from datetime import datetime\n",
    "\n",
    "#Training the model\n",
    "print(f'Beginning Training!')\n",
    "current_time = datetime.now()\n",
    "estimator.train(input_fn=train_input_fn, max_steps=num_train_steps)\n",
    "print(\"Training took time \", datetime.now() - current_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n",
      "/Users/magreco/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Starting evaluation at 2021-05-02T19:33:47Z\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Starting evaluation at 2021-05-02T19:33:47Z\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./bert_news_category/model.ckpt-550\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./bert_news_category/model.ckpt-550\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Finished evaluation at 2021-05-02-19:41:12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Finished evaluation at 2021-05-02-19:41:12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving dict for global step 550: eval_accuracy = 0.84416175, false_negatives = 33.0, false_positives = 63.0, global_step = 550, loss = 0.3891341, true_negatives = 49.0, true_positives = 2056.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving dict for global step 550: eval_accuracy = 0.84416175, false_negatives = 33.0, false_positives = 63.0, global_step = 550, loss = 0.3891341, true_negatives = 49.0, true_positives = 2056.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 550: ./bert_news_category/model.ckpt-550\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 550: ./bert_news_category/model.ckpt-550\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_accuracy': 0.84416175,\n",
       " 'false_negatives': 33.0,\n",
       " 'false_positives': 63.0,\n",
       " 'loss': 0.3891341,\n",
       " 'true_negatives': 49.0,\n",
       " 'true_positives': 2056.0,\n",
       " 'global_step': 550}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Evaluating the model with Validation set\n",
    "estimator.evaluate(input_fn=val_input_fn, steps=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###################################################################\n",
    "## BERT: Get The Vector Transformations from the Fine Tuned BERT ##\n",
    "# A method to get predictions\n",
    "def getPrediction(in_sentences, type_output = \"features\"):\n",
    "  #A list to map the actual labels to the predictions\n",
    "  labels = np.unique(train['label'])\n",
    "  input_examples = [run_classifier.InputExample(guid=\"\", text_a = x, text_b = None, label = 0) for x in in_sentences] \n",
    "  input_features = run_classifier.convert_examples_to_features(input_examples, label_list, MAX_SEQ_LENGTH, tokenizer)\n",
    "  #Predicting the classes \n",
    "  predict_input_fn = run_classifier.input_fn_builder(features=input_features, seq_length=MAX_SEQ_LENGTH, is_training=False, drop_remainder=False)\n",
    "  predictions = estimator.predict(predict_input_fn)\n",
    "  if type_output == \"features\":\n",
    "    return [prediction['pooled_output'] for _,prediction in enumerate(predictions) ]\n",
    "  else:\n",
    "    return ([(sentence, prediction['probabilities'],\n",
    "              prediction['labels'], labels[prediction['labels']]) for sentence, prediction in zip(in_sentences, predictions)])\n",
    "    \n",
    "tf.compat.v1.logging.set_verbosity(tf.logging.ERROR)\n",
    "MAX_SEQ_LENGTH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now extracting the representations [this takes a while on the unlabelled data]\n",
    "tr_emb = np.apply_along_axis(getPrediction, 0,np.array(train_df[DATA_COLUMN]))\n",
    "val_emb = np.apply_along_axis(getPrediction, 0,np.array(val_df[DATA_COLUMN]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are going to build a simple LSTM model having as input the vectors created before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emb</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>[[0.21529175, -0.7394364, -0.9999315, -0.40832...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>[[0.081997536, -0.70977426, -0.99962044, -0.21...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>[[-0.31381616, -0.7888122, -0.99862915, -0.038...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>[[-0.9431985, 0.14621414, 0.999251, 0.32380208...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>[[0.10378519, -0.69067234, -0.9997664, -0.4719...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 emb  label\n",
       "0  [[0.21529175, -0.7394364, -0.9999315, -0.40832...      1\n",
       "1  [[0.081997536, -0.70977426, -0.99962044, -0.21...      2\n",
       "2  [[-0.31381616, -0.7888122, -0.99862915, -0.038...      1\n",
       "3  [[-0.9431985, 0.14621414, 0.999251, 0.32380208...      0\n",
       "4  [[0.10378519, -0.69067234, -0.9997664, -0.4719...      1"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make the dataset for train and val:\n",
    "aux = -1\n",
    "len_l = 0\n",
    "train_x = {}\n",
    "for l, emb in zip(index_l, tr_emb):\n",
    "  if l in train_x.keys():\n",
    "    train_x[l]  =np.vstack([train_x[l], emb])\n",
    "  else:\n",
    "    train_x[l] = [emb]\n",
    "\n",
    "len(train_x.keys())\n",
    "\n",
    "\n",
    "train_l_final = []\n",
    "label_l_final = []\n",
    "for k in train_x.keys():\n",
    "  train_l_final.append(train_x[k])\n",
    "  label_l_final.append(train.loc[k]['label'])\n",
    "\n",
    "df_train = pd.DataFrame({'emb': train_l_final, 'label': label_l_final, })\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emb</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>[[-0.39435336, -0.3823846, -0.689411, -0.53040...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>[[-0.4020894, -0.6304336, -0.99605834, 0.47824...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>[[0.8609046, -0.47107053, -0.900671, -0.425417...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>[[0.9055058, -0.41222087, -0.710509, -0.607144...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>[[-0.14163546, -0.46758294, -0.98741376, -0.45...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 emb  label\n",
       "0  [[-0.39435336, -0.3823846, -0.689411, -0.53040...      1\n",
       "1  [[-0.4020894, -0.6304336, -0.99605834, 0.47824...      2\n",
       "2  [[0.8609046, -0.47107053, -0.900671, -0.425417...      2\n",
       "3  [[0.9055058, -0.41222087, -0.710509, -0.607144...      2\n",
       "4  [[-0.14163546, -0.46758294, -0.98741376, -0.45...      1"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aux = -1\n",
    "len_l = 0\n",
    "val_x = {}\n",
    "\n",
    "for l, emb in zip(val_index_l, val_emb):\n",
    "  if l in val_x.keys():\n",
    "    val_x[l]  =np.vstack([val_x[l], emb])\n",
    "  else:\n",
    "    val_x[l] = [emb]\n",
    "\n",
    "\n",
    "val_l_final = []\n",
    "vlabel_l_final = []\n",
    "for k in val_x.keys():\n",
    "  val_l_final.append(val_x[k])\n",
    "  vlabel_l_final.append(val.loc[k]['label'])\n",
    "\n",
    "df_val = pd.DataFrame({'emb': val_l_final, 'label': vlabel_l_final})\n",
    "df_val.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's keep part of the validation set for testing\n",
    "df_val, df_test = train_test_split(df_val, test_size=0.4, random_state=35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "text (InputLayer)            (None, None, 768)         0         \n",
      "_________________________________________________________________\n",
      "masking_1 (Masking)          (None, None, 768)         0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 100)               347600    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 30)                3030      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 3)                 93        \n",
      "=================================================================\n",
      "Total params: 350,723\n",
      "Trainable params: 350,723\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "### LSTM: Creating the Final Model ###\n",
    "\n",
    "from keras import layers\n",
    "from keras.layers import Input\n",
    "\n",
    "text_input = Input(shape=(None,768,), dtype='float32', name='text')\n",
    "\n",
    "l_mask = layers.Masking(mask_value=-99.)(text_input)\n",
    "# Which we encoded in a single vector via a LSTM\n",
    "encoded_text = layers.LSTM(100,)(l_mask)\n",
    "out_dense = layers.Dense(30, activation='relu')(encoded_text)\n",
    "# And we add a softmax classifier on top\n",
    "out = layers.Dense(len(label_list), activation='softmax')(out_dense)\n",
    "# At model instantiation, we specify the input and the output:\n",
    "model = Model(text_input, out)\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['acc'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember that when using a generator to train the model you have to fix the batch size and batches per epoch in order to guarantee that all of your data is passing in your training process. \n",
    "\n",
    "The following equation must hold:\n",
    "\n",
    "$length\\ of\\ data\\ =\\ number\\ of\\ batches\\ \\times\\ batches\\ per\\ epoch$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8803"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Length of training data\n",
    "num_sequences = len(df_train['emb'].to_list())\n",
    "num_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8802"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Since this is a prime number (how lucky!), we remove one row\n",
    "df_train = df_train.iloc[1:]\n",
    "num_sequences = len(df_train['emb'].to_list())\n",
    "num_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can determine the batch size and therefore the batches per epoch\n",
    "batch_size = 18\n",
    "batches_per_epoch =  489\n",
    "num_features= 768\n",
    "\n",
    "# Here's the generator function\n",
    "def train_generator(df):\n",
    "    x_list= df['emb'].to_list()\n",
    "    y_list =  df.label.to_list()\n",
    "    # Generate batches\n",
    "    while True:\n",
    "        for b in range(batches_per_epoch):\n",
    "            longest_index = (b + 1) * batch_size - 1\n",
    "            timesteps = len(max(df['emb'].to_list()[:(b + 1) * batch_size][-batch_size:], key=len))\n",
    "            x_train = np.full((batch_size, timesteps, num_features), -99.)\n",
    "            y_train = np.zeros((batch_size,  1))\n",
    "            for i in range(batch_size):\n",
    "                li = b * batch_size + i\n",
    "                x_train[i, 0:len(x_list[li]), :] = x_list[li]\n",
    "                y_train[i] = y_list[li]\n",
    "            yield x_train, y_train \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1320"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Length of validation data\n",
    "num_sequences_val = len(df_val['emb'].to_list())\n",
    "num_sequences_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can determine the batch size and therefore the batches per epoch\n",
    "batch_size_val = 15\n",
    "batches_per_epoch_val = 88\n",
    "num_features= 768\n",
    "\n",
    "\n",
    "# Here's the generator function\n",
    "def val_generator(df):\n",
    "    x_list= df['emb'].to_list()\n",
    "    y_list =  df.label.to_list()\n",
    "    # Generate batches\n",
    "    while True:\n",
    "        for b in range(batches_per_epoch_val):\n",
    "            longest_index = (b + 1) * batch_size_val - 1\n",
    "            timesteps = len(max(df['emb'].to_list()[:(b + 1) * batch_size_val][-31:], key=len))\n",
    "            # print(len(df_train['emb'].to_list()[:b+batch_size][-7:]))\n",
    "            x_train = np.full((batch_size_val, timesteps, num_features), -99.)\n",
    "            y_train = np.zeros((batch_size_val,  1))\n",
    "            for i in range(batch_size_val):\n",
    "                li = b * batch_size_val + i\n",
    "                # print(\"li\", li)\n",
    "                # print(x_train[i, 0:len(x_list[li]), :].shape, len(x_list[li]))\n",
    "                x_train[i, 0:len(x_list[li]), :] = x_list[li]\n",
    "                y_train[i] = y_list[li]\n",
    "            yield x_train, y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we can train the model, using the Kera’s callback named ReduceLROnPlateau which reduces the hyperparameter learning rate if the validation’s accuaracy does not improve over epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ReduceLROnPlateau\n",
    "call_reduce = ReduceLROnPlateau(monitor='val_acc', factor=0.95, patience=3, verbose=2,\n",
    "                                mode='auto', min_delta=0.01, cooldown=0, min_lr=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "489/489 [==============================] - 2s 3ms/step - loss: 0.2613 - acc: 0.9032 - val_loss: 0.2982 - val_acc: 0.8386\n",
      "Epoch 2/10\n",
      "489/489 [==============================] - 2s 3ms/step - loss: 0.2592 - acc: 0.9033 - val_loss: 0.2835 - val_acc: 0.8386\n",
      "Epoch 3/10\n",
      "489/489 [==============================] - 1s 3ms/step - loss: 0.2582 - acc: 0.9040 - val_loss: 0.2921 - val_acc: 0.8394\n",
      "Epoch 4/10\n",
      "489/489 [==============================] - 2s 3ms/step - loss: 0.2574 - acc: 0.9042 - val_loss: 0.2740 - val_acc: 0.8356\n",
      "\n",
      "Epoch 00004: ReduceLROnPlateau reducing learning rate to 0.0008145062311086804.\n",
      "Epoch 5/10\n",
      "489/489 [==============================] - 2s 3ms/step - loss: 0.2558 - acc: 0.9047 - val_loss: 0.2819 - val_acc: 0.8348\n",
      "Epoch 6/10\n",
      "489/489 [==============================] - 2s 3ms/step - loss: 0.2542 - acc: 0.9041 - val_loss: 0.2913 - val_acc: 0.8371\n",
      "Epoch 7/10\n",
      "489/489 [==============================] - 1s 3ms/step - loss: 0.2534 - acc: 0.9047 - val_loss: 0.2831 - val_acc: 0.8356\n",
      "\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.0007737808919046074.\n",
      "Epoch 8/10\n",
      "489/489 [==============================] - 2s 3ms/step - loss: 0.2523 - acc: 0.9039 - val_loss: 0.2940 - val_acc: 0.8318\n",
      "Epoch 9/10\n",
      "489/489 [==============================] - 1s 3ms/step - loss: 0.2509 - acc: 0.9047 - val_loss: 0.2960 - val_acc: 0.8326\n",
      "Epoch 10/10\n",
      "489/489 [==============================] - 2s 3ms/step - loss: 0.2499 - acc: 0.9051 - val_loss: 0.2951 - val_acc: 0.8295\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 0.000735091819660738.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x151014fd0>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit_generator(train_generator(df_train), steps_per_epoch=batches_per_epoch, epochs=10,\n",
    "                    validation_data=val_generator(df_val), validation_steps=batches_per_epoch_val, callbacks =[call_reduce] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "880"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Evaluating the model \n",
    "\n",
    "# Check length of test data first\n",
    "num_sequences_test = len(df_test['emb'].to_list())\n",
    "num_sequences_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "880"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Again a prime (how lucky!). Let's delete the first row\n",
    "df_test = df_test.iloc[1:]\n",
    "num_sequences_test = len(df_test['emb'].to_list())\n",
    "num_sequences_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5640871524810791, 0.8568181991577148]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Specify the usual values\n",
    "batch_size_val = 16\n",
    "batches_per_epoch_val = 55\n",
    "num_features = 768\n",
    "\n",
    "# Evaluate the model on 'unseen' data!\n",
    "model.evaluate_generator(val_generator(df_test), steps = batches_per_epoch_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model achieves an accuracy of $85.68\\%$ with a loss of $0.56$, which is good, even if not outstanding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classify articles\n",
    "We now use the model we just built in order to predict the label of the remaining sentences.\n",
    "The data must be cleaned a bit before, however.\n",
    "\n",
    "### Preparing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### FIRST LET'S GO BACK TO THE MAIN DATA ####\n",
    "import pickle\n",
    "with open(dir+'all_articles_topic.pkl', 'rb') as f:\n",
    "    articles = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop articles which are not classified under any topic\n",
    "df = articles.drop(articles[articles.Topic_Name == 'Unclassified 1'].index)\n",
    "df = df.drop(df[df.Topic_Name == 'Unclassified 8'].index)\n",
    "df = df.drop(df[df.Topic_Name == 'Unclassified 4'].index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now drop either too long or too short articles. The choice may make sense as sometimes there are 'articles' which in reality are daily updates. These updates are actually a collection of 'small' articles published from 7am till midnight, resulting in an incredibly long and quite uninformative (for the purpose of this project) article. Extremely short articles are simply useless and uninformative as well (maybe resulting from a scraping error).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/magreco/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "count    88121.000000\n",
       "mean       762.022753\n",
       "std        978.629785\n",
       "min          5.000000\n",
       "25%        371.000000\n",
       "50%        573.000000\n",
       "75%        846.000000\n",
       "max      39645.000000\n",
       "Name: LenText, dtype: float64"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Keep only two columns for now\n",
    "raw = df[['Transcript','Topic_Name']]\n",
    "\n",
    "# Length of articles\n",
    "raw['LenText'] = raw['Transcript'].str.split().str.len()\n",
    "# Distribution of length\n",
    "raw['LenText'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1521ce450>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## There are some extreme values\n",
    "# Articles in the last percentiles are too long and often just a summary of the day or so \n",
    "raw_check = raw.loc[raw['LenText']>=3500]\n",
    "raw_check['Topic_Name'].value_counts().sort_values(ascending=False).plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It's ok to drop these extremes\n",
    "df['LenText'] = df['Transcript'].str.split().str.len()\n",
    "df = df[df.LenText<=3500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x26281fbd0>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# And check too short ones (some letters to the editor, and other possible scraping mistakes)\n",
    "raw_check = raw.loc[raw['LenText']<=30]\n",
    "raw_check['Topic_Name'].value_counts().sort_values(ascending=False).plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Transcript</th>\n",
       "      <th>Topic_Name</th>\n",
       "      <th>LenText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>716</td>\n",
       "      <td>You imply that there is an academic conspiracy...</td>\n",
       "      <td>World Politics 3</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>992</td>\n",
       "      <td>PUBLICATION-TYPE: Newspaper   REGION: Nationa...</td>\n",
       "      <td>World Politics 3</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1097</td>\n",
       "      <td>PUBLICATION-TYPE: Newspaper    REGION: Nation...</td>\n",
       "      <td>World Politics 3</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>PUBLICATION-TYPE: Newspaper   REGION: Nationa...</td>\n",
       "      <td>World Politics 3</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1631</td>\n",
       "      <td>There is no meteorological reason why global w...</td>\n",
       "      <td>Climate, Science, Consequences</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>Moreover, wildlife experts now suggest that gl...</td>\n",
       "      <td>Climate, Science, Consequences</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1792</td>\n",
       "      <td>Is this due to metrication, because I don't th...</td>\n",
       "      <td>Climate, Science, Consequences</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2848</td>\n",
       "      <td>This is what comes of decades of virtue-signal...</td>\n",
       "      <td>Climate, Science, Consequences</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2849</td>\n",
       "      <td>This is what comes of decades of virtue-signal...</td>\n",
       "      <td>Climate, Science, Consequences</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2923</td>\n",
       "      <td>GRAPHIC: Reflections: Rab Butler  PUBLICATION-...</td>\n",
       "      <td>World Politics 3</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Transcript  \\\n",
       "716   You imply that there is an academic conspiracy...   \n",
       "992    PUBLICATION-TYPE: Newspaper   REGION: Nationa...   \n",
       "1097   PUBLICATION-TYPE: Newspaper    REGION: Nation...   \n",
       "1150   PUBLICATION-TYPE: Newspaper   REGION: Nationa...   \n",
       "1631  There is no meteorological reason why global w...   \n",
       "1700  Moreover, wildlife experts now suggest that gl...   \n",
       "1792  Is this due to metrication, because I don't th...   \n",
       "2848  This is what comes of decades of virtue-signal...   \n",
       "2849  This is what comes of decades of virtue-signal...   \n",
       "2923  GRAPHIC: Reflections: Rab Butler  PUBLICATION-...   \n",
       "\n",
       "                          Topic_Name  LenText  \n",
       "716                 World Politics 3       28  \n",
       "992                 World Politics 3        9  \n",
       "1097                World Politics 3        9  \n",
       "1150                World Politics 3        9  \n",
       "1631  Climate, Science, Consequences       28  \n",
       "1700  Climate, Science, Consequences       21  \n",
       "1792  Climate, Science, Consequences       20  \n",
       "2848  Climate, Science, Consequences       26  \n",
       "2849  Climate, Science, Consequences       26  \n",
       "2923                World Politics 3       13  "
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_check.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We arbitrarily get rid of articles with fewer than 20 words (it would be just a 2 lines article)\n",
    "df = df[df.LenText>20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Split each article into sentences\n",
    "\n",
    "# Getting s as pandas series which has split on full stop and space, and new sentence a new line\n",
    "s = df[\"Transcript\"].str.split('\\. ').apply(pd.Series,1).stack()\n",
    "s.index = s.index.droplevel(-1) # to line up with df's index\n",
    "s.name = 'Transcript' # needs a name to join\n",
    "\n",
    "# There are blank or empty cell values after above process. Removing them\n",
    "s.replace('', np.nan, inplace=True)\n",
    "s.replace(' ',np.nan, inplace=True)\n",
    "s.dropna(inplace=True)\n",
    "\n",
    "# Join now\n",
    "df_sent = df[['Transcript','Topic_Name','Document_No', 'Program Name']]\n",
    "del df_sent['Transcript']\n",
    "df_sent = df_sent.join(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repeat process for '?'\n",
    "s = df_sent[\"Transcript\"].str.split('\\? ').apply(pd.Series,1).stack()\n",
    "s.index = s.index.droplevel(-1) # to line up with df's index\n",
    "s.name = 'Transcript' # needs a name to join\n",
    "\n",
    "# There are blank or empty cell values after above process. Removing them\n",
    "s.replace('', np.nan, inplace=True)\n",
    "s.replace(' ',np.nan, inplace=True)\n",
    "s.dropna(inplace=True)\n",
    "\n",
    "# Join now\n",
    "df_sent2 = df[['Transcript','Topic_Name','Document_No', 'Program Name']]\n",
    "del df_sent2['Transcript']\n",
    "df_sent2 = df_sent2.join(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repeat process for '!'\n",
    "s = df_sent2[\"Transcript\"].str.split('\\! ').apply(pd.Series,1).stack()\n",
    "s.index = s.index.droplevel(-1) # to line up with df's index\n",
    "s.name = 'Transcript' # needs a name to join\n",
    "\n",
    "# There are blank or empty cell values after above process. Removing them\n",
    "s.replace('', np.nan, inplace=True)\n",
    "s.replace(' ',np.nan, inplace=True)\n",
    "s.dropna(inplace=True)\n",
    "\n",
    "# Join now\n",
    "df_sent3 = df[['Transcript','Topic_Name','Document_No', 'Program Name']]\n",
    "del df_sent3['Transcript']\n",
    "df_sent3 = df_sent3.join(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "### NOW WE GET RID OF TOO SHORT SENTENCES\n",
    "df_sent3['LenText'] = df_sent3['Transcript'].str.split().str.len()\n",
    "\n",
    "# These short sentences are meaningless. They don't matter anyway\n",
    "df_sent3 = df_sent3[df_sent3['LenText']>3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "### NOW GET RID OF OTHER USELESS SENTENCES\n",
    "# For various reasons there are sentences that we really don't want.\n",
    "# EG if article is from an online version and random sentences that link to other articles appear\n",
    "# Example: \"Read more: Obama meets Italian president tomorrow in Rome\"\n",
    "# Sentences like these are totally disconnected from the article\n",
    "# Let's drop them\n",
    "\n",
    "df_sent3 = df_sent3[~df_sent3.Transcript.str.contains(\"Captions:\")]\n",
    "df_sent3 = df_sent3[~df_sent3.Transcript.str.contains(\"Related:\")]\n",
    "df_sent3 = df_sent3[~df_sent3.Transcript.str.contains(\"Rating:\")]\n",
    "df_sent3 = df_sent3[~df_sent3.Transcript.str.contains(\"Read:\")]\n",
    "df_sent3 = df_sent3[~df_sent3.Transcript.str.contains(\"block-time\")]\n",
    "df_sent3 = df_sent3[~df_sent3.Transcript.str.contains(\"Animation:\")]\n",
    "df_sent3 = df_sent3[~df_sent3.Transcript.str.contains(\"·\")]\n",
    "df_sent3 = df_sent3[~df_sent3.Transcript.str.contains(\"Click to enlarge:\")]\n",
    "df_sent3 = df_sent3[~df_sent3.Transcript.str.contains(\"READ MORE:\")]\n",
    "df_sent3 = df_sent3[~df_sent3.Transcript.str.contains(\"Read more\")]\n",
    "df_sent3 = df_sent3[~df_sent3.Transcript.str.contains(\"In pictures:\")]\n",
    "df_sent3 = df_sent3[~df_sent3.Transcript.str.contains(\"Related articles\")]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "### GET RID OF MORE UNINFORMATIVE SENTENCES\n",
    "# From Nexis, in some cases at the end of the scraped articles there's a bunch of text related to the article tags\n",
    "# Example: \"GEOGRAPHY: ITALY.  TOPIC: POLITICS (50%); ENERGY (82%); CINEMA (12%)\"\n",
    "# I want to get rid of them\n",
    "\n",
    "# Function to detect number of upper cases characters in string\n",
    "def share_upper(s):\n",
    "    d={\"UPPER_CASE\":0, \"LOWER_CASE\":0}\n",
    "    for c in s:\n",
    "        if c.isupper():\n",
    "           d[\"UPPER_CASE\"]+=1\n",
    "        elif c.islower():\n",
    "           d[\"LOWER_CASE\"]+=1   \n",
    "        else:\n",
    "           pass\n",
    "    return d[\"UPPER_CASE\"]/(d[\"UPPER_CASE\"]+d[\"LOWER_CASE\"])\n",
    "\n",
    "# Function to detect number of letter characters in string\n",
    "def letters(s):\n",
    "    d={\"UPPER_CASE\":0, \"LOWER_CASE\":0}\n",
    "    for c in s:\n",
    "        if c.isupper():\n",
    "           d[\"UPPER_CASE\"]+=1\n",
    "        elif c.islower():\n",
    "           d[\"LOWER_CASE\"]+=1   \n",
    "        else:\n",
    "           pass\n",
    "    return d[\"UPPER_CASE\"]+d[\"LOWER_CASE\"]\n",
    "\n",
    "# Create column with number of letters\n",
    "df_sent3['letters'] = df_sent3['Transcript'].apply(lambda x:letters(x))\n",
    "\n",
    "# Get rid of sentences with less than 20 letters (letters, not charachters! they are uninformative)\n",
    "df_sent3 = df_sent3[df_sent3['letters']>20]\n",
    "\n",
    "# Create column with share of upper case letters\n",
    "df_sent3['share_upp'] = df_sent3['Transcript'].apply(lambda x:share_upper(x))\n",
    "\n",
    "# Drop if this share is higher than 50% [after manual check it makes sense]\n",
    "df_sent3 = df_sent3[df_sent3['share_upp']<=0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "### NOW GET RID OF DUPLICATE ARTICLES AND DUPLICATE SENTENCES WITHIN ARTICLES\n",
    "# Start by getting rid of duplicate sentences within articles\n",
    "df_sent3 = df_sent3.drop_duplicates(['Topic_Name','Document_No','Program Name', 'LenText','share_upp','letters'])\n",
    "\n",
    "# Now get rid of duplicate articles\n",
    "df_sent3 = df_sent3.drop_duplicates(['Topic_Name','Program Name','Transcript', 'LenText','share_upp','letters'])\n",
    "\n",
    "# Difference: 'Program Name' is the article title, 'Transcript' is the text of the sentence, and 'Document_No'\n",
    "# is a unique document identifier. Therefore:\n",
    "# 1- I drop duplicates sentences (indeed 'Transcript' is not in the 'drop_duplicates' arguments) while keeping the rest equal\n",
    "# 2- I drop duplicate articles (indeed 'Document_No' is not in the 'drop_duplicates' arguments) while keeping the rest equal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "### NOW YOU SHOULD SAVE SO IT'S READY FOR RE-USE AND ANALYSIS ###\n",
    "with open(dir+'data_sentences.pkl', 'wb') as f:\n",
    "    pickle.dump(df_sent3,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get predictions\n",
    "We can finally get the predicted labels for each sentence in this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import dataset\n",
    "with open(dir+'data_sentences.pkl', 'rb') as f:\n",
    "    db = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "## BERT: Get The Vector Transformations from the Fine Tuned BERT\n",
    "def getPrediction(in_sentences, type_output = \"features\"):\n",
    "  #A list to map the actual labels to the predictions\n",
    "  labels = np.unique(train['label'])\n",
    "  input_examples = [run_classifier.InputExample(guid=\"\", text_a = x, text_b = None, label = 0) for x in in_sentences] \n",
    "  input_features = run_classifier.convert_examples_to_features(input_examples, label_list, MAX_SEQ_LENGTH, tokenizer)\n",
    "  #Predicting the classes \n",
    "  predict_input_fn = run_classifier.input_fn_builder(features=input_features, seq_length=MAX_SEQ_LENGTH, is_training=False, drop_remainder=False)\n",
    "  predictions = estimator.predict(predict_input_fn)\n",
    "  if type_output == \"features\":\n",
    "    return [prediction['pooled_output'] for _,prediction in enumerate(predictions) ]\n",
    "  else:\n",
    "    return ([(sentence, prediction['probabilities'],\n",
    "              prediction['labels'], labels[prediction['labels']]) for sentence, prediction in zip(in_sentences, predictions)])\n",
    "    \n",
    "tf.compat.v1.logging.set_verbosity(tf.logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now extracting the representations [this takes a REAL while]\n",
    "db_emb = np.apply_along_axis(getPrediction, 0,np.array(db['Transcript']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each sentence in the original dataset is now converted to a 768-dimensional vector obtained from the fine-tuned BERT model. We can now get the predicted labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct dataset for prediction\n",
    "db_emb_final = []\n",
    "for i in range(0,db_emb.shape[0]):\n",
    "    db_emb_final = db_emb_final + [db_emb[i]]\n",
    "    \n",
    "df_pred = pd.DataFrame({'emb': db_emb_final})\n",
    "\n",
    "# Save it for future use\n",
    "with open(dir+'db_embreddings.pkl', 'wb') as f:\n",
    "    pickle.dump(df_pred,f)\n",
    "    \n",
    "def pred_generator(df):\n",
    "    x_list= df['emb'].to_list()\n",
    "    # Generate batches\n",
    "    while True:\n",
    "        for b in range(batches_per_epoch_val):\n",
    "            longest_index = (b + 1) * batch_size_val - 1\n",
    "            timesteps = len(max(df['emb'].to_list()[:(b + 1) * batch_size_val][-31:], key=len))\n",
    "            # print(len(df_train['emb'].to_list()[:b+batch_size][-7:]))\n",
    "            x_train = np.full((batch_size_val, timesteps, num_features), -99.)\n",
    "            for i in range(batch_size_val):\n",
    "                li = b * batch_size_val + i\n",
    "                # print(\"li\", li)\n",
    "                # print(x_train[i, 0:len(x_list[li]), :].shape, len(x_list[li]))\n",
    "                x_train[i, 0:len(x_list[li]), :] = x_list[li]\n",
    "            yield x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Use model to predict labels in expanded dataset\n",
    "num_sequences_test = len(df_pred['emb'].to_list())\n",
    "batch_size_val = 16\n",
    "batches_per_epoch_pred = 120823\n",
    "num_features = 768"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predictions\n",
    "predictions = model.predict_generator(pred_generator(df_pred), steps = batches_per_epoch_pred)\n",
    "\n",
    "# Create and store dataset\n",
    "predicted = pd.DataFrame(np.argmax(predictions,axis=1), columns = ['predicted'])\n",
    "\n",
    "with open(dir+'db_predictions2.pkl', 'wb') as f:\n",
    "    pickle.dump(predicted,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   predicted\n",
       "0          2\n",
       "1          2\n",
       "2          2\n",
       "3          2\n",
       "4          2"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What does this dataset look like?\n",
    "predicted.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Match these predictions to the original data\n",
    "# Reset the index of the original dataset\n",
    "db2 = db.reset_index(drop=True)\n",
    "\n",
    "# Merge dataset with predictions\n",
    "dball = pd.concat([db2,predicted], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic_Name</th>\n",
       "      <th>Document_No</th>\n",
       "      <th>Program Name</th>\n",
       "      <th>Transcript</th>\n",
       "      <th>LenText</th>\n",
       "      <th>letters</th>\n",
       "      <th>share_upp</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Taxes, UK Labour Market</td>\n",
       "      <td>0</td>\n",
       "      <td>Business blasts Brown on the burden of tax col...</td>\n",
       "      <td>Wilcox's sentiments echo those of thousands of...</td>\n",
       "      <td>9</td>\n",
       "      <td>55</td>\n",
       "      <td>0.018182</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Taxes, UK Labour Market</td>\n",
       "      <td>0</td>\n",
       "      <td>Business blasts Brown on the burden of tax col...</td>\n",
       "      <td>And in three weeks, UK plc's anger at the admi...</td>\n",
       "      <td>19</td>\n",
       "      <td>89</td>\n",
       "      <td>0.044944</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Taxes, UK Labour Market</td>\n",
       "      <td>0</td>\n",
       "      <td>Business blasts Brown on the burden of tax col...</td>\n",
       "      <td>The Treasury Select Committee is to probe how ...</td>\n",
       "      <td>14</td>\n",
       "      <td>77</td>\n",
       "      <td>0.064935</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Taxes, UK Labour Market</td>\n",
       "      <td>0</td>\n",
       "      <td>Business blasts Brown on the burden of tax col...</td>\n",
       "      <td>A series of fierce submissions to the committe...</td>\n",
       "      <td>38</td>\n",
       "      <td>179</td>\n",
       "      <td>0.033520</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Taxes, UK Labour Market</td>\n",
       "      <td>0</td>\n",
       "      <td>Business blasts Brown on the burden of tax col...</td>\n",
       "      <td>The Institute of Directors, the Federation for...</td>\n",
       "      <td>34</td>\n",
       "      <td>186</td>\n",
       "      <td>0.059140</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Topic_Name  Document_No  \\\n",
       "0  Taxes, UK Labour Market            0   \n",
       "1  Taxes, UK Labour Market            0   \n",
       "2  Taxes, UK Labour Market            0   \n",
       "3  Taxes, UK Labour Market            0   \n",
       "4  Taxes, UK Labour Market            0   \n",
       "\n",
       "                                        Program Name  \\\n",
       "0  Business blasts Brown on the burden of tax col...   \n",
       "1  Business blasts Brown on the burden of tax col...   \n",
       "2  Business blasts Brown on the burden of tax col...   \n",
       "3  Business blasts Brown on the burden of tax col...   \n",
       "4  Business blasts Brown on the burden of tax col...   \n",
       "\n",
       "                                          Transcript  LenText  letters  \\\n",
       "0  Wilcox's sentiments echo those of thousands of...        9       55   \n",
       "1  And in three weeks, UK plc's anger at the admi...       19       89   \n",
       "2  The Treasury Select Committee is to probe how ...       14       77   \n",
       "3  A series of fierce submissions to the committe...       38      179   \n",
       "4  The Institute of Directors, the Federation for...       34      186   \n",
       "\n",
       "   share_upp  predicted  \n",
       "0   0.018182          2  \n",
       "1   0.044944          2  \n",
       "2   0.064935          2  \n",
       "3   0.033520          2  \n",
       "4   0.059140          2  "
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What does this dataset look like?\n",
    "dball.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic_Name</th>\n",
       "      <th>Document_No</th>\n",
       "      <th>Title</th>\n",
       "      <th>Transcript</th>\n",
       "      <th>words</th>\n",
       "      <th>letters</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Taxes, UK Labour Market</td>\n",
       "      <td>0</td>\n",
       "      <td>Business blasts Brown on the burden of tax col...</td>\n",
       "      <td>Wilcox's sentiments echo those of thousands of...</td>\n",
       "      <td>9</td>\n",
       "      <td>55</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Taxes, UK Labour Market</td>\n",
       "      <td>0</td>\n",
       "      <td>Business blasts Brown on the burden of tax col...</td>\n",
       "      <td>And in three weeks, UK plc's anger at the admi...</td>\n",
       "      <td>19</td>\n",
       "      <td>89</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Taxes, UK Labour Market</td>\n",
       "      <td>0</td>\n",
       "      <td>Business blasts Brown on the burden of tax col...</td>\n",
       "      <td>The Treasury Select Committee is to probe how ...</td>\n",
       "      <td>14</td>\n",
       "      <td>77</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Taxes, UK Labour Market</td>\n",
       "      <td>0</td>\n",
       "      <td>Business blasts Brown on the burden of tax col...</td>\n",
       "      <td>A series of fierce submissions to the committe...</td>\n",
       "      <td>38</td>\n",
       "      <td>179</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Taxes, UK Labour Market</td>\n",
       "      <td>0</td>\n",
       "      <td>Business blasts Brown on the burden of tax col...</td>\n",
       "      <td>The Institute of Directors, the Federation for...</td>\n",
       "      <td>34</td>\n",
       "      <td>186</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Topic_Name  Document_No  \\\n",
       "0  Taxes, UK Labour Market            0   \n",
       "1  Taxes, UK Labour Market            0   \n",
       "2  Taxes, UK Labour Market            0   \n",
       "3  Taxes, UK Labour Market            0   \n",
       "4  Taxes, UK Labour Market            0   \n",
       "\n",
       "                                               Title  \\\n",
       "0  Business blasts Brown on the burden of tax col...   \n",
       "1  Business blasts Brown on the burden of tax col...   \n",
       "2  Business blasts Brown on the burden of tax col...   \n",
       "3  Business blasts Brown on the burden of tax col...   \n",
       "4  Business blasts Brown on the burden of tax col...   \n",
       "\n",
       "                                          Transcript  words  letters  \\\n",
       "0  Wilcox's sentiments echo those of thousands of...      9       55   \n",
       "1  And in three weeks, UK plc's anger at the admi...     19       89   \n",
       "2  The Treasury Select Committee is to probe how ...     14       77   \n",
       "3  A series of fierce submissions to the committe...     38      179   \n",
       "4  The Institute of Directors, the Federation for...     34      186   \n",
       "\n",
       "   predicted  \n",
       "0          2  \n",
       "1          2  \n",
       "2          2  \n",
       "3          2  \n",
       "4          2  "
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Do some adjustments\n",
    "\n",
    "# Rename columns\n",
    "dball = dball.rename(columns={\"Program Name\": \"Title\", \"LenText\": \"words\"})\n",
    "\n",
    "# Drop useless column\n",
    "dball = dball.drop(['share_upp'], axis=1)\n",
    "\n",
    "# New look\n",
    "dball.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Source</th>\n",
       "      <th>Date</th>\n",
       "      <th>Program Name</th>\n",
       "      <th>Transcript</th>\n",
       "      <th>trans_pp</th>\n",
       "      <th>Document_No</th>\n",
       "      <th>Dominant_Topic</th>\n",
       "      <th>Topic_Perc_Contrib</th>\n",
       "      <th>Keywords</th>\n",
       "      <th>Transcript2</th>\n",
       "      <th>Topic_Name</th>\n",
       "      <th>Topic_Map</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>The Sunday Telegraph (LONDON)</td>\n",
       "      <td>February 01, 2004, Sunday</td>\n",
       "      <td>Business blasts Brown on the burden of tax col...</td>\n",
       "      <td>Wilcox's sentiments echo those of thousands of...</td>\n",
       "      <td>wilcox sentiments echo thousands businessmen t...</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.2123</td>\n",
       "      <td>tax, labour, year, rise, economy, price, pay, ...</td>\n",
       "      <td>Wilcox's sentiments echo those of thousands of...</td>\n",
       "      <td>Taxes, UK Labour Market</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>The Sunday Telegraph (LONDON)</td>\n",
       "      <td>February 08, 2004, Sunday</td>\n",
       "      <td>In search of another global calamity</td>\n",
       "      <td>APOCALYPSES in Maggie Gee's fiction are of the...</td>\n",
       "      <td>apocalypses maggie gee fiction peg variety vog...</td>\n",
       "      <td>1</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.4143</td>\n",
       "      <td>child, age, woman, also, family, include, year...</td>\n",
       "      <td>APOCALYPSES in Maggie Gee's fiction are of the...</td>\n",
       "      <td>Unclassified 8</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>The Sunday Telegraph (LONDON)</td>\n",
       "      <td>December 05, 2004, Sunday</td>\n",
       "      <td>All in the best possible taste (mostly) Whethe...</td>\n",
       "      <td>Nigella Lawson has made her name with the same...</td>\n",
       "      <td>nigella lawson made name kind gourmandist gust...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3062</td>\n",
       "      <td>say, get, people, make, time, go, take, think,...</td>\n",
       "      <td>Nigella Lawson has made her name with the same...</td>\n",
       "      <td>Unclassified 1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>The Sunday Telegraph (LONDON)</td>\n",
       "      <td>December 12, 2004, Sunday</td>\n",
       "      <td>Flooding: don't let our defences down Resident...</td>\n",
       "      <td>Residents also dispute the accuracy of the Env...</td>\n",
       "      <td>residents also dispute accuracy environment ag...</td>\n",
       "      <td>3</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.4409</td>\n",
       "      <td>flood, water, say, people, area, home, storm, ...</td>\n",
       "      <td>Residents also dispute the accuracy of the Env...</td>\n",
       "      <td>Extreme Weather Events</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>The Sunday Telegraph (LONDON)</td>\n",
       "      <td>December 12, 2004, Sunday</td>\n",
       "      <td>Save the world, ignore global warming</td>\n",
       "      <td>Global warming will mainly harm the developing...</td>\n",
       "      <td>global warming mainly harm developing countrie...</td>\n",
       "      <td>4</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.2346</td>\n",
       "      <td>would, may, even, many, claim, believe, make, ...</td>\n",
       "      <td>Global warming will mainly harm the developing...</td>\n",
       "      <td>World Politics 3</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Source                       Date  \\\n",
       "0  The Sunday Telegraph (LONDON)  February 01, 2004, Sunday   \n",
       "1  The Sunday Telegraph (LONDON)  February 08, 2004, Sunday   \n",
       "2  The Sunday Telegraph (LONDON)  December 05, 2004, Sunday   \n",
       "3  The Sunday Telegraph (LONDON)  December 12, 2004, Sunday   \n",
       "4  The Sunday Telegraph (LONDON)  December 12, 2004, Sunday   \n",
       "\n",
       "                                        Program Name  \\\n",
       "0  Business blasts Brown on the burden of tax col...   \n",
       "1               In search of another global calamity   \n",
       "2  All in the best possible taste (mostly) Whethe...   \n",
       "3  Flooding: don't let our defences down Resident...   \n",
       "4              Save the world, ignore global warming   \n",
       "\n",
       "                                          Transcript  \\\n",
       "0  Wilcox's sentiments echo those of thousands of...   \n",
       "1  APOCALYPSES in Maggie Gee's fiction are of the...   \n",
       "2  Nigella Lawson has made her name with the same...   \n",
       "3  Residents also dispute the accuracy of the Env...   \n",
       "4  Global warming will mainly harm the developing...   \n",
       "\n",
       "                                            trans_pp  Document_No  \\\n",
       "0  wilcox sentiments echo thousands businessmen t...            0   \n",
       "1  apocalypses maggie gee fiction peg variety vog...            1   \n",
       "2  nigella lawson made name kind gourmandist gust...            2   \n",
       "3  residents also dispute accuracy environment ag...            3   \n",
       "4  global warming mainly harm developing countrie...            4   \n",
       "\n",
       "   Dominant_Topic  Topic_Perc_Contrib  \\\n",
       "0             6.0              0.2123   \n",
       "1             7.0              0.4143   \n",
       "2             0.0              0.3062   \n",
       "3            14.0              0.4409   \n",
       "4            22.0              0.2346   \n",
       "\n",
       "                                            Keywords  \\\n",
       "0  tax, labour, year, rise, economy, price, pay, ...   \n",
       "1  child, age, woman, also, family, include, year...   \n",
       "2  say, get, people, make, time, go, take, think,...   \n",
       "3  flood, water, say, people, area, home, storm, ...   \n",
       "4  would, may, even, many, claim, believe, make, ...   \n",
       "\n",
       "                                         Transcript2               Topic_Name  \\\n",
       "0  Wilcox's sentiments echo those of thousands of...  Taxes, UK Labour Market   \n",
       "1  APOCALYPSES in Maggie Gee's fiction are of the...           Unclassified 8   \n",
       "2  Nigella Lawson has made her name with the same...           Unclassified 1   \n",
       "3  Residents also dispute the accuracy of the Env...   Extreme Weather Events   \n",
       "4  Global warming will mainly harm the developing...         World Politics 3   \n",
       "\n",
       "   Topic_Map  \n",
       "0       14.0  \n",
       "1        8.0  \n",
       "2        1.0  \n",
       "3       10.0  \n",
       "4        3.0  "
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Add information about source and date\n",
    "\n",
    "# Need original data with all articles\n",
    "with open(dir+'all_articles_topic.pkl', 'rb') as f:\n",
    "    articles = pickle.load(f)\n",
    "    \n",
    "articles.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic_Name</th>\n",
       "      <th>Document_No</th>\n",
       "      <th>Title</th>\n",
       "      <th>Transcript</th>\n",
       "      <th>words</th>\n",
       "      <th>letters</th>\n",
       "      <th>predicted</th>\n",
       "      <th>Source</th>\n",
       "      <th>Date</th>\n",
       "      <th>Keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Taxes, UK Labour Market</td>\n",
       "      <td>0</td>\n",
       "      <td>Business blasts Brown on the burden of tax col...</td>\n",
       "      <td>Wilcox's sentiments echo those of thousands of...</td>\n",
       "      <td>9</td>\n",
       "      <td>55</td>\n",
       "      <td>2</td>\n",
       "      <td>The Sunday Telegraph (LONDON)</td>\n",
       "      <td>February 01, 2004, Sunday</td>\n",
       "      <td>tax, labour, year, rise, economy, price, pay, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Taxes, UK Labour Market</td>\n",
       "      <td>0</td>\n",
       "      <td>Business blasts Brown on the burden of tax col...</td>\n",
       "      <td>And in three weeks, UK plc's anger at the admi...</td>\n",
       "      <td>19</td>\n",
       "      <td>89</td>\n",
       "      <td>2</td>\n",
       "      <td>The Sunday Telegraph (LONDON)</td>\n",
       "      <td>February 01, 2004, Sunday</td>\n",
       "      <td>tax, labour, year, rise, economy, price, pay, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Taxes, UK Labour Market</td>\n",
       "      <td>0</td>\n",
       "      <td>Business blasts Brown on the burden of tax col...</td>\n",
       "      <td>The Treasury Select Committee is to probe how ...</td>\n",
       "      <td>14</td>\n",
       "      <td>77</td>\n",
       "      <td>2</td>\n",
       "      <td>The Sunday Telegraph (LONDON)</td>\n",
       "      <td>February 01, 2004, Sunday</td>\n",
       "      <td>tax, labour, year, rise, economy, price, pay, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Taxes, UK Labour Market</td>\n",
       "      <td>0</td>\n",
       "      <td>Business blasts Brown on the burden of tax col...</td>\n",
       "      <td>A series of fierce submissions to the committe...</td>\n",
       "      <td>38</td>\n",
       "      <td>179</td>\n",
       "      <td>2</td>\n",
       "      <td>The Sunday Telegraph (LONDON)</td>\n",
       "      <td>February 01, 2004, Sunday</td>\n",
       "      <td>tax, labour, year, rise, economy, price, pay, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Taxes, UK Labour Market</td>\n",
       "      <td>0</td>\n",
       "      <td>Business blasts Brown on the burden of tax col...</td>\n",
       "      <td>The Institute of Directors, the Federation for...</td>\n",
       "      <td>34</td>\n",
       "      <td>186</td>\n",
       "      <td>2</td>\n",
       "      <td>The Sunday Telegraph (LONDON)</td>\n",
       "      <td>February 01, 2004, Sunday</td>\n",
       "      <td>tax, labour, year, rise, economy, price, pay, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Topic_Name  Document_No  \\\n",
       "0  Taxes, UK Labour Market            0   \n",
       "1  Taxes, UK Labour Market            0   \n",
       "2  Taxes, UK Labour Market            0   \n",
       "3  Taxes, UK Labour Market            0   \n",
       "4  Taxes, UK Labour Market            0   \n",
       "\n",
       "                                               Title  \\\n",
       "0  Business blasts Brown on the burden of tax col...   \n",
       "1  Business blasts Brown on the burden of tax col...   \n",
       "2  Business blasts Brown on the burden of tax col...   \n",
       "3  Business blasts Brown on the burden of tax col...   \n",
       "4  Business blasts Brown on the burden of tax col...   \n",
       "\n",
       "                                          Transcript  words  letters  \\\n",
       "0  Wilcox's sentiments echo those of thousands of...      9       55   \n",
       "1  And in three weeks, UK plc's anger at the admi...     19       89   \n",
       "2  The Treasury Select Committee is to probe how ...     14       77   \n",
       "3  A series of fierce submissions to the committe...     38      179   \n",
       "4  The Institute of Directors, the Federation for...     34      186   \n",
       "\n",
       "   predicted                         Source                       Date  \\\n",
       "0          2  The Sunday Telegraph (LONDON)  February 01, 2004, Sunday   \n",
       "1          2  The Sunday Telegraph (LONDON)  February 01, 2004, Sunday   \n",
       "2          2  The Sunday Telegraph (LONDON)  February 01, 2004, Sunday   \n",
       "3          2  The Sunday Telegraph (LONDON)  February 01, 2004, Sunday   \n",
       "4          2  The Sunday Telegraph (LONDON)  February 01, 2004, Sunday   \n",
       "\n",
       "                                            Keywords  \n",
       "0  tax, labour, year, rise, economy, price, pay, ...  \n",
       "1  tax, labour, year, rise, economy, price, pay, ...  \n",
       "2  tax, labour, year, rise, economy, price, pay, ...  \n",
       "3  tax, labour, year, rise, economy, price, pay, ...  \n",
       "4  tax, labour, year, rise, economy, price, pay, ...  "
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create sub-data to merge with necessary information (including topic keywords)\n",
    "art_toMerge = articles[['Source','Date','Keywords','Document_No']]\n",
    "\n",
    "# Create final dataset\n",
    "dball2 = pd.merge(dball,art_toMerge, on='Document_No', how='left')\n",
    "\n",
    "dball2.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It would be useful now to check whether it actually worked or not. Let's sample few sentences that should be labelled as *skeptic* (we do the hard test immediately). If these are correctly classified, it's already a good sign and we can imagine that also classification of *environmental* and *unrepresentative* sentences also worked. Why? Because the *skeptic* ones were severely underrepresented in the training sample! Remember? There were roughly 500 *skeptic* sentences for taining, compared to over 4000 *environmental* and 6000 *unrepresentative*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53     So action on global warming is basically a very costly way of doing very little for much richer ...\n",
       "71     So in a curious way, global warming really is the moral test of our time, but not in the way its...\n",
       "456                          \"Global warming - at least the modern nightmare version - is a myth,\" he said\n",
       "460                                            They say this is global warming: I say this is poppycock.\" \n",
       "472    \"Even the idea of modelling climate change is mostly theoretical at the moment, so it is impossi...\n",
       "522    Media reaction to both the original scientific paper and our short comment in Nature magazine il...\n",
       "546                                                                     Mainstream science was unimpressed\n",
       "680    For some reason, this isn't true in climatology - or at least, so those scientists working on gl...\n",
       "723    A similar picture has emerged with icebergs, whose increasing numbers have been taken as proof t...\n",
       "724    New research suggests that the trend is largely due to changes in counting methods, and provides...\n",
       "Name: Transcript, dtype: object"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is an option in order for the string not to be truncated (so that we can read more of the output)\n",
    "pd.options.display.max_colwidth = 100\n",
    "\n",
    "# Sample the 'skeptic' sentences\n",
    "negatives = dball2.loc[dball2['predicted']==0]\n",
    "\n",
    "# Check if they are actually skeptic\n",
    "negatives['Transcript'].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like it worked! Recall that the model's accuracy is around $85\\%$ therefore it's possible that some sentences will be wrongly classified. However this is already a very good result! As we can see the sentences above all seem to diplay some doubtful statements about climate science."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1931241    He warned his party against taking pleasure in the Lib Dems' collapse, saying voters have become...\n",
       "1170595        \"It's easy enough to start with the 100,000 internal flights: make the train network comparable\n",
       "564615     Beaufort County Sheriff's LieutenantColonel Neil Baxley said that South Carolina county was prep...\n",
       "726236     Unique landscapes Machair, a grassy coastal habitat found only in north-west Scotland and the we...\n",
       "1644956    But we know there are challenges ahead in the face of climate change and threats from new, invas...\n",
       "1751993    The Canadian leader said that despite Trump's pledge to pull the US out of the North American Fr...\n",
       "1300745    The US hasn't regulated yet but federal policy is drifting in the wrong direction,\" said Logomasini\n",
       "446254                       The world population was 5.47bn, of whom 77 per cent were in developing countries\n",
       "1266889    Dorothy Thompson, chief executive of Drax, the biggest coal-fired power station in the UK, said ...\n",
       "585507                                                                          Counter-trends are harder news\n",
       "Name: Transcript, dtype: object"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sample 'environmental' sentences\n",
    "positives = dball2.loc[dball2['predicted']==1]\n",
    "positives = positives.sample(n=10, random_state = 100)\n",
    "\n",
    "# Check if they are actually in line with climate science\n",
    "positives['Transcript'].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, I would have hoped for a better outcome. There seems to be some *uninformative* stuff in there as well, therefore some misclassification. The hope is that at the article level we can get a good representation (though with some noise) of the amount of pro-climate science or pro-skeptic views within newspapers. Don't forget to save your dataset for analysis!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export\n",
    "with open(dir+\"dbFinal.pkl\", 'wb') as f:\n",
    "    pickle.dump(dball2, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
